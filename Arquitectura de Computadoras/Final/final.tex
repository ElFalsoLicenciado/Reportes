\documentclass{article}
\usepackage[export]{adjustbox}
\usepackage[spanish]{babel}
\usepackage[letterpaper,top=1.5cm,bottom=2cm,left=2cm,right=2cm,marginparwidth=1.5cm]{geometry}
\usepackage[strict]{changepage}
\usepackage[normalem]{ulem}
\usepackage[T1]{fontenc}
\usepackage{apacite,xurl,hyperref,pdfpages,graphicx,sectsty,ragged2e}
\usepackage[inkscapelatex=false]{svg}
\usepackage{float,array,listings,enumitem,subcaption,charter,amsfonts,amsthm,amsmath,mathtools}
\newtheorem{theorem}{Caso}
\sectionfont{\huge{}\underline\centering}
\subsectionfont{\LARGE{}\centering\textit}
\subsubsectionfont{\LARGE{}\centering\textbf}
\usepackage[affil-it]{authblk}
\renewcommand\Authfont{\fontsize{20}{25}\selectfont}
\usepackage[tablename=Tabla ]{caption}
\usepackage[figurename=Imagen ]{caption}
\newcommand{\R}{\mathbb{R}}
\newcommand{\tab}{$\quad$}

\begin{document}
\includepdf{portada lab.pdf}

\justifying

\Large
\tableofcontents\newpage

\Large

    \section{Introducción.}
    
        El procesamiento paralelo es un método del campo de la computación que permite que dos o más procesadores de una computadora se utilicen para trabajar en partes separadas de una tarea. De esta manera, es posible reducir el tiempo dedicado a resolver el problema.\newline

        El concepto de computación paralela comenzó a desarrollarse a finales de la década de 1950 por investigadores de IBM. Ellos creían que una sola computadora no satisfaría la creciente demanda de potencia de procesamiento. Una posible solución sería tener dos procesadores (o núcleos) trabajando simultáneamente.\newline

        El primer chip comercial con múltiples núcleos fue el IBM Power4, lanzado en 2001. El procesador, basado en la arquitectura PowerPC, era un dual-core con una frecuencia de 1,1 a 1,3 GHz. La CPU, que fue la primera en tener dos núcleos en un solo chip de silicio, se fabricaba en una litografía de 180 nanómetros.\newline

        Hay varias formas diferentes de computación paralela: Paralelismo a nivel de bit, paralelismo a nivel de instrucción, paralelismo de datos y paralelismo de tareas. El paralelismo se ha empleado durante muchos años, sobre todo en la computación de altas prestaciones, pero el interés en ella ha crecido últimamente debido a las limitaciones físicas que impiden el aumento de la frecuencia. Como el consumo de energía —y por consiguiente la generación de calor— de las computadoras constituye una preocupación en los últimos años, la computación en paralelo se ha convertido en el paradigma dominante en la arquitectura de computadores, principalmente en forma de procesadores multinúcleo.\newline

        \begin{figure}[H]
            \centering
            \includegraphics[width=0.5 \linewidth]{img/ProcesamientoParalelo1.png}
            \caption{Imagen de ilustracion.}
        \end{figure}

    \section{Taxonomía de Flynn.}
        
        La taxonomía de Flynn es un sistema de clasificación de arquitecturas que se basa en la idea de cuántos flujos de instrucciones y cuántos flujos de datos puede manipular una computadora simultáneamente. Fue creada por el científico de la computación Michael J. Flynn en 1966 y se utiliza hasta el día de hoy en el concepto de computación paralela.\newline

        El flujo de instrucciones es una secuencia de instrucciones ejecutadas por el procesador. Una instrucción es una “orden” dada al chip para realizar una operación específica, como una adición o una resta. Cuando tenemos varias órdenes consecutivas, tenemos un flujo de instrucciones.\newline

        Por otro lado, el flujo de datos es el conjunto de datos sobre los cuales se ejecutan las instrucciones. Volviendo al ejemplo matemático anterior, los números que se sumarían o restarían serían el flujo de datos en un procesador.\newline


        La taxonomía de Flynn divide los sistemas en cuatro categorías:

        \begin{itemize}
            \item \textbf{SISD} (Single Instruction, Single Data): es el modelo de computadora más simple, en el cual una sola instrucción opera en un solo flujo de datos. La mayoría de los primeros chips funcionaban de esta manera.
            
            \item \textbf{MISD} (Multiple Instruction, Single Data): varias instrucciones se ejecutan sobre los mismos datos. Es un modelo teórico e inusual en el mundo real.
            
            \item \textbf{SIMD} (Single Instruction, Multiple Data): una sola instrucción se aplica a varios flujos de datos simultáneamente. Puede ser útil en procesadores vectoriales, como los utilizados en NPUs para inteligencia artificial.
            
            \item \textbf{MIMD} (Multiple Instruction, Multiple Data): varias instrucciones operan en varios flujos de datos. Es el modelo más utilizado en los procesadores modernos con múltiples núcleos y se puede encontrar en todas las categorías de dispositivos electrónicos, desde pequeños teléfonos inteligentes hasta grandes servidores.
        \end{itemize}
    
        \newpage

        \subsection{SISD (Single Instruction, Single Data)}
            Flujo único de instrucciones y flujo único de datos. Una computadora secuencial que no aprovecha el paralelismo ni en las instrucciones ni en los flujos de datos. La unidad de control único (CU) obtiene un único flujo de instrucciones (IS) de la memoria. Luego, la CU genera señales de control apropiadas para dirigir un solo elemento de procesamiento (PE) para operar en un solo flujo de datos (DS), es decir, una operación a la vez.\newline

            Ejemplos de arquitecturas SISD son las máquinas tradicionales de un solo procesador, como las computadoras personales (PC) más antiguas (en 2010, muchas PC tenían varios núcleos) y las computadoras centrales.

            \begin{figure}[H]
                \centering
                \includegraphics[width=0.35 \linewidth]{img/SISD.png}
                \caption{Diseño de la categoría SISD.}
            \end{figure}
        
        \subsection{SIMD (Single Instruction, Multiple Data)}
            Flujo de instrucción simple y flujo de datos múltiple. Esto significa que una única instrucción es aplicada sobre diferentes datos al mismo tiempo. En las máquinas de este tipo, varias unidades de procesado diferentes son invocadas por una única unidad de control. Al igual que las MISD, las SIMD soportan procesamiento vectorial (matricial) asignando cada elemento del vector a una unidad funcional diferente para procesamiento concurrente.\newline

            El artículo de Flynn de 1972 subdividió SIMD en tres categorías adicionales:\newline

            \begin{itemize}
                \item \textbf{Procesador de rayos}: Estos reciben la instrucción (samo) pero cada unidad de procesamiento paralelo tiene su propio archivo de memoria y registro separado y distinto.
                
                \item \textbf{Procesador de tuberías}: Estos reciben la instrucción (samo) pero luego leen los datos de un recurso central, cada uno procesa fragmentos de esos datos, luego escribe los resultados al mismo recurso central. En la Figura 5 del papel de Flynn 1972 que el recurso es la memoria principal: para las CPU modernas que el recurso es ahora más típicamente el archivo de registro.
                
                \item \textbf{Procesador asociado}: Estos reciben la instrucción (samo) pero en cada unidad de procesamiento paralelo una independiente se toma la decisión sobre la base de datos local a la unidad, en cuanto a si realizar la ejecución o si saltarla. En terminología moderna esto se conoce como "predicado" (masked) SIMD.
            \end{itemize}


            \begin{figure}[H]
                \centering
                \includegraphics[width=0.35 \linewidth]{img/SIMD.png}
                \caption{Diseño de la categoría SIMD.}
            \end{figure}


        \subsection{MISD (Multiple Instruction, Single Data)}
            Flujo múltiple de instrucciones y único flujo de datos. Esto significa que varias instrucciones actúan sobre el mismo y único trozo de datos. Este tipo de máquinas se pueden interpretar de dos maneras. Una es considerar la clase de máquinas que requerirían que unidades de procesamiento diferentes recibieran instrucciones distintas operando sobre los mismos datos. Esta clase de arquitectura ha sido clasificada por numerosos arquitectos de computadores como impracticable o imposible, y en estos momentos no existen ejemplos que funcionen siguiendo este modelo. \newline
            
            Las arquitecturas segmentadas, o encauzadas, realizan el procesamiento vectorial a través de una serie de etapas, cada una ejecutando una función particular produciendo un resultado intermedio. La razón por la cual dichas arquitecturas son clasificadas como MISD es que los elementos de un vector pueden ser considerados como pertenecientes al mismo dato, y todas las etapas del cauce representan múltiples instrucciones que son aplicadas sobre ese vector.

            \begin{figure}[H]
                \centering
                \includegraphics[width=0.35 \linewidth]{img/MISD.png}
                \caption{Diseño de la categoría MISD.}
            \end{figure}

        \subsection{MIMD (Multiple Instruction, Multiple Data)}
            Flujo de instrucciones múltiple y flujo de datos múltiple. Son máquinas que poseen varias unidades procesadoras en las cuales se pueden realizar múltiples instrucciones sobre datos diferentes de forma simultánea. Las MIMD son las más complejas, pero son también las que potencialmente ofrecen una mayor eficiencia en la ejecución concurrente o paralela. Aquí la concurrencia implica que no sólo hay varios procesadores operando simultáneamente, sino que además hay varios programas (procesos) ejecutándose también al mismo tiempo.

            \begin{figure}[H]
                \centering
                \includegraphics[width=0.35 \linewidth]{img/MIMD.png}
                \caption{Diseño de la categoría MIMD.}
            \end{figure}

        \subsection{Resumen}
            \begin{figure}[H]
                \centering
                \includegraphics[width=0.8 \linewidth]{img/Resumen Flynn.png}
                \caption{Resumen de los diseños de cada taxonmía}
            \end{figure}
    
    \section{Multiprocesamiento.}
        Multiprocesamiento o multiproceso es el uso de dos o más procesadores (CPU) en una computadora para la ejecución de uno o varios procesos (programas corriendo). Algunas personas, en el idioma español hacen sinónimo este término con el de multitareas (del inglés multitasking) el cual consiste en la ejecución de uno o más procesos concurrentes en un sistema. Así como la multitarea permite a múltiples procesos compartir una única CPU, múltiples CPU pueden ser utilizados para ejecutar múltiples procesos o múltiples hilos (threads) dentro de un único proceso.\newline

        El multiprocesamiento se ha empleado desde los años 60 en los entornos de cómputo de alto rendimiento; a pesar de esto, durante muchos años no muchos tomaban esta área de especialización, una computadora que contara con más de un procesador era cara y debido a esto muchos decidían no hacer uso de más de un procesador. Hasta que en 2005 y después de cumplirse 40 años del modelo conocido como Ley de Moore, se empezaron a exceder los 3 GHz de velocidad de esta manera creando problemas de calentamiento motivando el uso de múltiples procesadores. \newpage


        \subsection{Simétrico (SMP)}
            El multiprocesamiento simétrico o multiprocesamiento de memoria compartida (SMP) involucra una arquitectura de hardware y software de computadora multiprocesador donde dos o más procesadores idénticos están conectados a una sola memoria principal compartida, tienen acceso total a todos los dispositivos de entrada y salida, y están controlados por una sola instancia del sistema operativo que trata a todos los procesadores por igual, sin reservar ninguno para propósitos especiales. La mayoría de los sistemas multiprocesador actuales utilizan una arquitectura SMP. En el caso de los procesadores multinúcleo, la arquitectura SMP se aplica a los núcleos y los trata como procesadores independientes.\newline

            Los sistemas SMP permiten que cualquier procesador trabaje en cualquier tarea sin importar su localización en memoria; con un propicio soporte del sistema operativo, estos sistemas pueden mover fácilmente tareas entre los procesadores para garantizar eficientemente el trabajo.\newline

            \begin{figure}[H]
                \centering
                \includegraphics[width=0.7 \linewidth]{img/SMP.png}
                \caption{Diseño del tipo SMP}
            \end{figure}

            \newpage

        \subsection{Heterogéneo}
            Se refiere a un enfoque de computación que utiliza diferentes tipos de procesadores o arquitecturas para llevar a cabo tareas específicas. Este método permite aprovechar las fortalezas de cada tipo de procesador, como CPUs, GPUs y FPGAs, optimizando así el rendimiento y la eficiencia energética. En el contexto de sistemas distribuidos y procesamiento de datos, el procesamiento heterogéneo se vuelve crucial, ya que permite la ejecución de cargas de trabajo diversas en entornos que requieren escalabilidad y flexibilidad.

        \subsection{Cluster}
            Un clúster es un tipo de arquitectura paralela distribuida que consiste de un conjunto de computadores independientes interconectados operando de forma conjunta como único recurso computacional sin embargo, cada computador puede utilizarse de forma independiente o separada.\newline

            En esta arquitectura, el computador paralelo es esencialmente una colección de procesadores secuenciales, cada uno con su propia memoria local, que pueden trabajar conjuntamente.\vspace{3px}

            \begin{itemize}
                \item Cada nodo tiene rápido acceso a su propia memoria y acceso a la memoria de otros nodos mediante una red de comunicaciones, habitualmente una red de comunicaciones de alta velocidad. 

                \item Los datos son intercambiados entre los nodos como mensajes a través de la red. 

                \item Una red de ordenadores, especialmente si disponen de una interconexión de alta velocidad, puede ser vista como un multicomputador de memoria distribuida y como tal ser utilizada para resolver problemas mediante computación paralela.
            \end{itemize} \vspace{3px}

            La construcción de los ordenadores del clúster es más fácil y económica debido a su flexibilidad: pueden tener toda la misma configuración de hardware y sistema operativo diferente rendimiento pero con arquitectura y sistemas operativos similares o tener diferente hardware y sistema operativo lo que hace más fácil y económica su construcción. Para que un clúster funcione como tal no basta solo con conectar entre si los ordenadores, sino que es necesario proveer un sistema de manejo del clúster, el cual se encargue de interactuar con el usuario y los procesos que ocurren en él para optimizar el funcionamiento. 


    \section{Tipos de paralelismo.}
        Una de las características clave del multiprocesamiento es la capacidad de realizar múltiples tareas al mismo tiempo. Esto se logra al distribuir las tareas entre los diferentes procesadores, lo que permite una mayor eficiencia en el manejo de la carga de trabajo.\newline
        
        El paralelismo puede estudiarse a varios niveles:

        \begin{itemize}
            \item \textbf{Trabajo}: Dos programas distintos pueden ejecutarse en paralelo.
            
            \item \textbf{Tarea}: En este nivel se consideran varias tareas independientes entre si formando parte de un programa determinado. Es posible la interacción de las tareas.
            
            \item \textbf{Proceso}: Varios procesos componen una tarea. Son bloques con funcionalidad bien definida.
            
            \item \textbf{Variable}: El paralelismo puede darse a nivel de variables ya que varias instrucciones pueden ser ejecutadas en paralelo siendo el punto de conflicto las variables en común.
            
            \item \textbf{Bit}: Todos los computadores usan paralelismo a nivel de bit.
        \end{itemize}\vspace{5px}


        Algunos ámbitos en los que se usa la computación paralela.\vspace{5px}
        
        \begin{itemize}
            \item Simulación de modelos complejos
            
            \item Diseño y automatización de proyectos de ingeniería
            
            \item Exploración petrolera y minera
            
            \item Medicina
            
            \item Área militar
            
            \item Cine: efectos visuales, animación 3D
            
            \item Realidad Virtual
            
            \item Comercio electrónico
            
            \item Mega bases de datos (google, youtube, rapidshare)
        \end{itemize}

        \subsection{A nivel de bit}
            Se habla de paralelismo al nivel de bit, cuando se aumenta el tamaño de la palabra del procesador (tamaño de la cadena de bits a procesar). Este aumento reduce el número de instrucciones que tiene que ejecutar el procesador en variables cuyos tamaños sean mayores a la longitud de la cadena.\newline
            
            Ejemplo: En un procesador de 8-bits sumar dos números de 16bits tomaría dos instrucciones. En un procesador de 16-bits esa operación requiere solo una instrucción.\newline

            Desde el advenimiento de la integración a gran escala (VLSI) como tecnología de fabricación de chips de computadora en la década de 1970 hasta alrededor de 1986, la aceleración en la arquitectura de computadores se lograba en gran medida duplicando el tamaño de la palabra en la computadora, la cantidad de información que el procesador puede manejar por ciclo.\newline

            El aumento del tamaño de la palabra reduce el número de instrucciones que el procesador debe ejecutar para realizar una operación en variables cuyos tamaños son mayores que la longitud de la palabra.\newline

            Históricamente, los microprocesadores de 4 bits fueron sustituidos por unos de 8 bits, luego de 16 bits y 32 bits, esta tendencia general llegó a su fin con la introducción de procesadores de 64 bits, lo que ha sido un estándar en la computación de propósito general durante la última década.
        
        \subsection{A nivel de instrucción}
            Un programa de ordenador es, en esencia, una secuencia de instrucciones ejecutadas por un procesador. Estas instrucciones pueden reordenarse y combinarse en grupos que luego son ejecutadas en paralelo sin cambiar el resultado del programa. Esto se conoce como paralelismo a nivel de instrucción. Los avances en el paralelismo a nivel de instrucción dominaron la arquitectura de computadores desde mediados de 1980 hasta mediados de la década de 1990.\newline

            Los procesadores modernos tienen ''pipeline'' de instrucciones de varias etapas. Cada etapa en el pipeline corresponde a una acción diferente que el procesador realiza en la instrucción correspondiente a la etapa; un procesador con un pipelinede N etapas puede tener hasta n instrucciones diferentes en diferentes etapas de finalización.\newline

            Además del paralelismo a nivel de instrucción del pipelining, algunos procesadores pueden ejecutar más de una instrucción a la vez. Estos son conocidos como procesadores superescalares. Las instrucciones pueden agruparse juntas sólo si no hay dependencia de datos entre ellas.

        \subsection{De datos}
            El paralelismo de datos es el paralelismo inherente en programas con ciclos, que se centra en la distribución de los datos entre los diferentes nodos computacionales que deben tratarse en paralelo. La paralelización de ciclos conduce a menudo a secuencias similares de operaciones —no necesariamente idénticas— o funciones que se realizan en los elementos de una gran estructura de datos. Muchas de las aplicaciones científicas y de ingeniería muestran paralelismo de datos.\newline

            Una dependencia de terminación de ciclo es la dependencia de una iteración de un ciclo en la salida de una o más iteraciones anteriores. Las dependencias de terminación de ciclo evitan la paralelización de ciclos.\newline

            Extensiones vectoriales como SSE, AVX o NEON permiten aplicar una misma instrucción sobre varios datos simultáneos. Es ideal para operaciones uniformes sobre arreglos: procesamiento de imágenes, señales o vectores numéricos. Requiere que los datos estén alineados y que las operaciones sean homogéneas para evitar divergencias.\vspace{5px}
            
            \begin{itemize}
                \item \textbf{Beneficio}: gran aumento del throughput (cantidad de trabajo completado por unidad de tiempo) sin aumentar el número de hilos.
                
                \item \textbf{Condiciones}: datos contiguos y alineados, bucles vectorizables y pocas dependencias.
                
                \item \textbf{Limitación}: código con muchas ramas o acceso irregular a memoria pierde eficiencia vectorial.
            \end{itemize}
            \newpage

        \subsection{De tareas}
            Divide el problema en tareas independientes que pueden ejecutarse en paralelo. Cada tarea puede tener diferente trabajo y duración. Se implementa con hilos, pools de tareas o frameworks específicos. Funciona bien cuando el problema se puede fragmentar en unidades que comparten poco estado y pueden balancearse entre núcleos.\newline

            El desafío principal es el balanceo de carga: tareas muy desiguales dejan núcleos ociosos. Estrategias como dividir en unidades más pequeñas (work stealing) ayudan a usar todo el hardware disponible.
    
    \section{Cuestionario.}
        \begin{enumerate}
            \item \textbf{¿Qué caracteriza a la arquitectura MIMD?} \textit{Se caracteriza por tener múltiples flujos de instrucciones y múltiples flujos de datos, permitiendo que varios procesadores ejecuten diferentes instrucciones sobre distintos datos de forma simultánea.}
            
            \item \textbf{Las arquitecturas MIMD permiten la ejecución concurrente de varios programas al mismo tiempo.} \textit{Verdadero} 
            
            \item \textbf{¿Cuál de las siguientes arquitecturas es la más compleja pero también la más eficiente para ejecución paralela?} 
            \textit{\begin{enumerate}
                \renewcommand{\labelenumi}{\alph{enumi})}
                \item SISD
                \item SIMD
                \item MISMD
                \item MIMD
            \end{enumerate}}
            \textit{Respuesta correcta: d) MIMD}

            \item \textbf{¿Qué es el multiprocesamiento?} \textit{Es el uso de dos o más procesadores (CPU) en una computadora para ejecutar uno o varios procesos de manera simultánea.}
            
            \item \textbf{Multiprocesamiento y multitarea significan exactamente lo mismo.
            } \textit{Falso}
            \newpage

            \item \textbf{¿Cuál fue una de las principales razones para el auge del multiprocesamiento después de 2005?} \textit{Las limitaciones de velocidad por calentamiento al superar los 3 GHz, lo que motivó el uso de múltiples procesadores en lugar de aumentar la frecuencia.}
            
            \item \textbf{¿Qué ley se menciona en relación con el crecimiento del hardware y sus límites?
            } \textit{
                \begin{enumerate}
                    \renewcommand{\labelenumi}{\alph{enumi})}
                    \item Ley de Amdahl
                    \item Ley de Shannon
                    \item Ley de Moore
                    \item Ley de Newton
                \end{enumerate}}
            \textit{Respuesta correcta: c) Ley de Moore}
            
            \item \textbf{¿Qué es un sistema SMP?} \textit{Es una arquitectura de multiprocesamiento simétrico donde varios procesadores idénticos comparten una sola memoria principal y están controlados por un único sistema operativo.}
            
            \item \textbf{En un sistema SMP, algunos procesadores están reservados para tareas especiales.} \textit{Falso}
            
            \item \textbf{¿Qué componente comparten todos los procesadores en una arquitectura SMP?} \textit{
                \begin{enumerate}
                    \renewcommand{\labelenumi}{\alph{enumi})}
                    \item Caché privada
                    \item Memoria principal
                    \item Sistema Operativo distinto
                    \item GPU dedicada
                \end{enumerate}}
            \textit{Respuesta correcta: b) Memoria principal}
            
            \item \textbf{¿Qué significa multiprocesamiento heterogéneo?} \textit{Es un enfoque que utiliza diferentes tipos de procesadores o arquitecturas (CPU, GPU, FPGA) para ejecutar tareas específicas aprovechando sus fortalezas.}
            
            \item \textbf{El procesamiento heterogéneo ayuda a mejorar la eficiencia energética y el rendimiento.
            } \textit{Verdadero}
            
            \item \textbf{¿Qué es un clúster de computadoras?} \textit{Es una arquitectura paralela distribuida formada por computadoras independientes interconectadas que trabajan juntas como un único recurso computacional.}
            \newpage            

            \item \textbf{¿Cómo intercambian datos los nodos de un clúster?} \textit{
                \begin{enumerate}
                    \renewcommand{\labelenumi}{\alph{enumi})}
                    \item Mensajes a través de la red
                    \item Registros internos
                    \item Memoria compartida
                    \item Caché global
                \end{enumerate}}
            \textit{Respuesta correcta: a) Mensajes a través de la red}

            \item \textbf{Un clúster solo funciona si todos los nodos tienen exactamente el mismo hardware y sistema operativo.} \textit{Falso}
            
            \item \textbf{¿Qué es el paralelismo a nivel de bit?} \textit{Es el paralelismo que se logra aumentando el tamaño de la palabra del procesador, permitiendo procesar más bits por instrucción.}
            
            \item \textbf{¿Qué tamaño de palabra es el estándar actual en la computación de propósito general?} \textit{
                \begin{enumerate}
                    \renewcommand{\labelenumi}{\alph{enumi})}
                    \item 16 bits
                    \item 32 bits
                    \item 64 bits
                    \item 128 bits
                \end{enumerate}}
            \textit{Respuesta correcta: c) 64 bits}
            
            \item \textbf{El paralelismo a nivel de bit reduce el número de instrucciones necesarias para operar con datos grandes.} \textit{Verdadero}
            
            \item \textbf{¿Qué es el paralelismo a nivel de instrucción?} \textit{Es la ejecución simultánea de varias instrucciones reorganizadas de manera que no alteren el resultado del programa.}
            
            \item \textbf{¿Cómo se llama la técnica que divide la ejecución de una instrucción en varias etapas?} \textit{
                \begin{enumerate}
                    \renewcommand{\labelenumi}{\alph{enumi})}
                    \item Multitarea
                    \item Pipeline
                    \item Clustering
                    \item Vectorización
                \end{enumerate}}
            \textit{Respuesta correcta: b) Pipeline}
            
            \item \textbf{Los procesadores superescalares pueden ejecutar más de una instrucción al mismo tiempo.} \textit{Verdadero}
            
            \item \textbf{¿Qué es el paralelismo de datos?} \textit{Es la ejecución paralela de operaciones similares sobre distintos elementos de una estructura de datos, común en ciclos y aplicaciones científicas.}
            
            \item \textbf{¿Qué extensiones permiten aplicar una instrucción a varios datos simultáneamente?} \textit{
                \begin{enumerate}
                    \renewcommand{\labelenumi}{\alph{enumi})}
                    \item HTTP, FTP
                    \item BIOS, UEFI
                    \item RAID, LVM
                    \item SSE, AVX, NEO 
                \end{enumerate}}
            \textit{Respuesta correcta: d) SSE, AVX, NEO}

            \item \textbf{El código con muchas ramas pierde eficiencia en el paralelismo vectorial.} \textit{Verdadero}
            
            \item \textbf{¿Cuál es el principal desafío del paralelismo de tareas?} \textit{El balanceo de carga, ya que tareas desiguales pueden dejar algunos núcleos ociosos.}
            
        \end{enumerate}


    \section{Conclusión.}
        La computación paralela y el multiprocesamiento representan una evolución clave en la arquitectura de los sistemas de cómputo modernos. A través de taxonomías como SISD, SIMD, MISD y MIMD, así como de arquitecturas como SMP, sistemas heterogéneos y clústeres, es posible aprovechar mejor los recursos de hardware para ejecutar múltiples instrucciones y procesar grandes volúmenes de datos de manera simultánea. Los distintos tipos de paralelismo (a nivel de bit, instrucción, datos y tareas) permiten optimizar el rendimiento, la eficiencia y la escalabilidad de los sistemas, siendo fundamentales en áreas científicas, industriales y comerciales actuales.

    \newpage
    
    \section{Bibliografía.}
    \begin{enumerate}
        \item Adictech. (2024, April 9). ¿Qué es la Computación Paralela?: Beneficios y Aplicaciones. Adictec - Adicción Por La Tecnología. \url{https://adictec.com/que-es-computacion-paralela/}

        \item de, B. (2025). Curso - 4.1 Aspectos Básicos de la Computación Paralela. Google.com. \url{https://sites.google.com/itmexicali.edu.mx/arquitectura-de-computadoras/4-procesamiento-paralelo/4-1-aspectos-b%C3%A1sicos-de-la-computaci%C3%B3n-paralela}

        \item Taxonomía de Flynn AcademiaLab. (2024). Academia-Lab.com. \url{https://academia-lab.com/enciclopedia/taxonomia-de-flynn/}

        \item de, T. (2025). Curso - 4.2 Tipos de Computación Paralela. Google.com. \url{https://sites.google.com/itmexicali.edu.mx/arquitectura-de-computadoras/4-procesamiento-paralelo/4-2-tipos-de-computaci%C3%B3n-paralela?authuser=0}

        \item de, C. (2005, February 13). uso de dos o más procesadores (CPU) en una computadora para la ejecución de uno o varios procesos. Wikipedia.org; Wikimedia Foundation, Inc. \url{https://es.wikipedia.org/wiki/Multiprocesamiento}

        \item Multiprocesamiento simétrico AcademiaLab. (2024). Academia-Lab.com. \url{https://academia-lab.com/enciclopedia/multiprocesamiento-simetrico/}

        \item Procesamiento Heterogu00e9neo. (2025). Glosarix. \url{https://glosarix.com/glossary/procesamiento-heterogeneo/}
        
        \item de, S. (2025). Curso - 4.4 Sistemas de Memoria Distribuida. Multicomputadores: Clusters. Google.com. \url{https://sites.google.com/itmexicali.edu.mx/arquitectura-de-computadoras/4-procesamiento-paralelo/4-4-sistemas-de-memoria-distribuida-multicomputadores-clusters?authuser=0}
        
        \item Todo sobre el multiprocesamiento: definición y tipos más comunes. (2024). Venceya.com. \url{https://venceya.com/multiprocesamiento-en-que-consiste-tipos/}
        
        \item Introducción a las Arquitecturas Paralelas. (n.d.). \url{https://users.exa.unicen.edu.ar/catedras/arqui2/arqui2/filminas/Introduccion%20a%20las%20arquitecturas%20Paralelas.pdf}

‌        \item Programación Paralela. (2017). Github.io. \url{https://ferestrepoca.github.io/paradigmas-de-programacion/paralela/paralela_teoria/index.html#thirteen}

        \item Moisset, D. (2025). Arquitecturas de Paralelismo. Tutorialesprogramacionya.com. \url{https://www.tutorialesprogramacionya.com/computacionparalelaconcurrente/introduccion/tema4.html}
        ‌ 
    \end{enumerate}

‌
‌
\end{document}